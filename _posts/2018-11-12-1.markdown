---
layout: post
title:  "python入门，处理矩阵遇到的问题及自己的解决方案!"
---


#python入门开发 
作为一个入门的机器学习小白，希望可以将自己学习中遇到的一些问题与大家分享，减少大家入坑时间及早跳出bug。
因为自己也是第一次写博客，所以希望有任何问题请大家指出，博主会加以改进。

今天主要讲的是矩阵的处理以及采用AdaBoost集成学习模型进行的分类预测。
开发工具：python pyCharm scikit-learn numpy， 具体安装流程就请各位自行百度啦。

为什么要从矩阵处理入手呢，那是因为在机器的世界里，万物皆可为向量。向量其实也算是一维的矩阵，我们的训练数据和要预测的数据都是以矩阵的形式传输给机器的。这是就需要numpy和pandas这两个非常出名的科学计算库。
先来描述一下我的工作吧。主要就是利用随钻数据进行岩性识别，简单一点来讲就是将机器学习应用到石油行业。目前共有600组随钻数据，每一组数据包含三个特征量。每一组数据对应着一个岩性标签。
因为博主前期一直处理的是一组数据对应一个标签，做类似的分类问题，但在完成开发之后为了使得岩性数据有一定的概括性，因为地层比较复杂，具体也不详细描述，所以博主需要采用滑动窗口法，从第一组数据开始读取五组数据，将这五组数据看作是一个二维矩阵，作为分类器的输入，再将这个二维矩阵给出对应的一个岩性标签。笼统一点来讲就是要利用五组数据作为一个输入，然后给定一个标签。关于滑动窗口法这里给大家一个链接，可以仔细参考。也可以参照下面给出的代码来按照我的方法进行滑动窗口方法取数据。依据每五组数据作为一个矩阵，每行依次取向下取五组，对于600组数据来讲共有596个二维矩阵作为输入。对应也将会有596个岩性标签与之对应。→[基于滑动窗口的流式数据处理示例](https://www.cnblogs.com/chenergougou/p/7120024.html)
今天主要介绍两个内容：一个是读取数据的方式，另外一个是将三维数据降维，进行分类器运算。
####读取数据的方式

```
# 先构建一个596*5*3的三维数组
A_1 = [0]*3
A_2 = [A_1]*5
A = [A_2]*596
# np.loadtxt()是用于从文本加载数据.文本文件中的每一行必须含有相同的数据
# 因为我的data_3.txt文件是600组数据,所以利用np.loadtxt()得到的数据的维数
a = np.loadtxt('data_3.txt')
# print(a)
# 接下来的操作就是将600组数据通过滑动窗口法得到596个二维矩阵,并存入一个三维矩阵中
for row in range(0,596):
    col1 = row
    col2 = row+5
    A[row] = a[col1:col2]
```
给大家提一个小小的建议，如果在开发过程中不清楚输入数据的类型一定要及时将其print出来及时处理。
######这样我就将600组数据通过滑动窗口法的形式转变为596个5*3的二维矩阵啦。是不是很开心呢！！！
#####但是处理好之后将数据传送给AdaBoos分类器时发现该分类器貌似不支持矩阵形式输入，这就很尴尬，所以博主发现还需要将之前处理好的数据进行降维操作。
这是可能大家就会很好奇，又要降维那之前为什么还要构建一个三维矩阵了，是这样的博主的能力有限，目前想到利用滑动窗口法取的数据只能这样处理，如果大家有好的办法希望可以告知。<认真脸>
####降维操作
这里的降维其实就是与别的博客里写的降维操作还不一样，这里是将取好的5*3的二维矩阵的数据拼接在一起构成一个列表，这样就可以成功进入分类器中啦。
这里博主采用的是“留出法”将数据集二等分，其中298组数据作为训练集训练分类器。这里来讲一下如何提取训练集。博主这里的方法也比较水，但是谁不是从小白进阶的呢？

```
x_train = []
i = 0
while i < 596:
    temp = np.array(A[i])
    nx, ny = temp.shape
    temp = temp.reshape(nx * ny)
    x_train.append(temp.tolist())
    i = i+2
```
另外附分类器的训练代码

```
bdt_real = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=3),
    n_estimators=500,
    learning_rate=1)
bdt_real.fit(x_train, y_train)

```

这样训练集就成功构建，就可以将此输入到分类器中得到完美的预测啦。
###ok，就是这样，读取数据的方式以及降维操作，如果大家还有什么以问还可以来找博主，共同进步✌。




